# -*- coding: utf-8 -*-
"""am10000_efficientnetB0_with_metadata(72.39%).ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1w9VxPUSXcTCKD-rookbYcDj1WP93mQIX
"""

from google.colab import drive
import os

print("Mounting Google Drive...")
drive.mount('/content/drive')
print("Google Drive mounted successfully.")

zip_path = '/content/drive/MyDrive/archive2.zip' # Assuming HAM10000 is in archive2.zip

if os.path.exists(zip_path):
    print("\nUnzipping ham10000 dataset...")
    os.makedirs('ham10000_data', exist_ok=True)
    os.system(f'unzip -q "{zip_path}" -d ham10000_data/')
    print("Unzipping completed successfully.")
else:
    print(f"\nError: The file was not found at the specified path: {zip_path}")

import pandas as pd
import numpy as np
import tensorflow as tf
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.utils.class_weight import compute_class_weight

# --- Define Parameters ---
base_dir = 'ham10000_data'
IMG_SIZE = 224
BATCH_SIZE = 64
NUM_CLASSES = 7
EPOCHS = 40

# --- Load and Preprocess Metadata ---
print("Loading and preprocessing metadata...")
metadata_df = pd.read_csv(os.path.join(base_dir, 'HAM10000_metadata.csv'))

# Fill missing age values with the average age
metadata_df['age'].fillna(metadata_df['age'].mean(), inplace=True)

# One-Hot Encode categorical features
metadata_df = pd.get_dummies(metadata_df, columns=['sex', 'localization'], drop_first=True)

# Scale the age feature
scaler = StandardScaler()
metadata_df['age'] = scaler.fit_transform(metadata_df[['age']])

# --- Prepare image paths and labels (same as before) ---
image_folders = [os.path.join(base_dir, f) for f in os.listdir(base_dir) if 'images' in f]
all_image_paths = {os.path.splitext(f)[0]: os.path.join(folder, f) for folder in image_folders for f in os.listdir(folder)}
metadata_df['image_path'] = metadata_df['image_id'].map(all_image_paths.get)
class_names = metadata_df['dx'].unique()
label_map = {label: i for i, label in enumerate(class_names)}
metadata_df['label'] = metadata_df['dx'].map(label_map.get)

# --- Split the data ---
# We now need to split the image paths, the metadata, and the labels
train_df, val_df = train_test_split(
    metadata_df, test_size=0.2, random_state=42, stratify=metadata_df['label']
)

# Isolate the metadata columns we will use
meta_features = [col for col in train_df.columns if col not in ['lesion_id', 'image_id', 'dx', 'dx_type', 'image_path', 'label']]
train_meta = train_df[meta_features].astype('float32')
val_meta = val_df[meta_features].astype('float32')

# --- Calculate Class Weights ---
class_weights = compute_class_weight('balanced', classes=np.unique(train_df['label']), y=train_df['label'])
class_weights_dict = dict(enumerate(class_weights))
print("Calculated Class Weights:", class_weights_dict)

# --- Create a new tf.data pipeline for two inputs ---
def load_and_preprocess(path, meta, label):
    # Load image
    image = tf.io.read_file(path)
    image = tf.image.decode_jpeg(image, channels=3)
    image = tf.image.resize(image, [IMG_SIZE, IMG_SIZE])
    # Return a dictionary of inputs
    return {'image_input': image, 'meta_input': meta}, label

AUTOTUNE = tf.data.AUTOTUNE
train_dataset = tf.data.Dataset.from_tensor_slices((train_df['image_path'], train_meta, train_df['label']))
train_dataset = train_dataset.map(load_and_preprocess, num_parallel_calls=AUTOTUNE)
train_dataset = train_dataset.shuffle(1024).batch(BATCH_SIZE).prefetch(AUTOTUNE)

validation_dataset = tf.data.Dataset.from_tensor_slices((val_df['image_path'], val_meta, val_df['label']))
validation_dataset = validation_dataset.map(load_and_preprocess, num_parallel_calls=AUTOTUNE)
validation_dataset = validation_dataset.batch(BATCH_SIZE).prefetch(AUTOTUNE)

print("\nMulti-input datasets created successfully.")

import tensorflow as tf

# --- Image Branch (CNN) ---
base_model = tf.keras.applications.EfficientNetB0(
    include_top=False, weights='imagenet', input_shape=(IMG_SIZE, IMG_SIZE, 3)
)
base_model.trainable = False
image_input = tf.keras.layers.Input(shape=(IMG_SIZE, IMG_SIZE, 3), name='image_input')
x_img = tf.keras.applications.efficientnet.preprocess_input(image_input)
x_img = base_model(x_img, training=False)
x_img = tf.keras.layers.GlobalAveragePooling2D()(x_img)
x_img = tf.keras.layers.Dropout(0.3)(x_img)

# --- Metadata Branch (MLP) ---
meta_input = tf.keras.layers.Input(shape=(len(meta_features),), name='meta_input')
x_meta = tf.keras.layers.Dense(32, activation='relu')(meta_input)
x_meta = tf.keras.layers.Dense(16, activation='relu')(x_meta)

# --- Combine Branches ---
combined = tf.keras.layers.concatenate([x_img, x_meta])
combined = tf.keras.layers.Dropout(0.4)(combined)
combined = tf.keras.layers.Dense(64, activation='relu')(combined)

# --- Final Classifier ---
outputs = tf.keras.layers.Dense(NUM_CLASSES, activation='softmax')(combined)

# Create the final model with two inputs
model = tf.keras.Model(inputs=[image_input, meta_input], outputs=outputs)
model.summary()

model.compile(
    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),
    loss='sparse_categorical_crossentropy',
    metrics=['accuracy']
)

early_stopping = tf.keras.callbacks.EarlyStopping(
    monitor='val_loss', patience=5, restore_best_weights=True
)

print("\nStarting multi-modal model training...")
history = model.fit(
    train_dataset,
    epochs=EPOCHS,
    validation_data=validation_dataset,
    class_weight=class_weights_dict,
    callbacks=[early_stopping]
)

print("\nStarting final evaluation...")
loss, accuracy = model.evaluate(validation_dataset)

print("\n" + "="*40)
print("     Final Results on the Validation Set")
print("="*40)
print(f"Loss: {loss:.4f}")
print(f"Accuracy: {accuracy * 100:.2f}%")
print("="*40)